{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kXqg-4alzi_H"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-0FuaNKt7en",
        "outputId": "8484cac1-dc00-415c-f63e-6e34687e5491"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: Ubuntu Dialogue Corpus\n",
        "https://github.com/rkadlec/ubuntu-ranking-dataset-creator/tree/master"
      ],
      "metadata": {
        "id": "QPKcyB1k3K2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rkadlec/ubuntu-ranking-dataset-creator.git\n",
        "\n",
        "%cd ubuntu-ranking-dataset-creator/\n",
        "\n",
        "!mv [source_folder_path] /content/\n",
        "\n",
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQApK6_N3LAh",
        "outputId": "5a57d979-2658-4f08-883e-c078d510f9e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ubuntu-ranking-dataset-creator'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Total 107 (delta 0), reused 0 (delta 0), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (107/107), 3.61 MiB | 6.49 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "/content/ubuntu-ranking-dataset-creator\n",
            "mv: cannot stat '[source_folder_path]': No such file or directory\n",
            "drive  sample_data  ubuntu-ranking-dataset-creator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up the necessary libraries/modules and checks whether CUDA (GPU support) is available, assigning the appropriate device (\"cuda\" or \"cpu\") for computation:"
      ],
      "metadata": {
        "id": "rT4TMRKkvq54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install torch-geometric\n",
        "\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xzMb1SWh3Yq",
        "outputId": "966993b3-9b35-4543-d469-3884cd10cb54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "2.1.0+cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8_1ROHTzi_P"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries/modules\n",
        "import torch  # PyTorch library for deep learning\n",
        "from torch.jit import script, trace  # For script and trace in PyTorch\n",
        "import torch.nn as nn  # Neural network module in PyTorch\n",
        "from torch import optim  # Optimisation module in PyTorch\n",
        "import torch.nn.functional as F  # Functional operations for neural networks\n",
        "import csv  # Comma Separated Values (CSV) file handling\n",
        "import random  # Random number generation\n",
        "import re  # Regular expressions for text processing\n",
        "import os  # Operating system interface\n",
        "import unicodedata  # Unicode character database\n",
        "import codecs  # Codec support for reading and writing text files\n",
        "from io import open  # Input/output operations with text files\n",
        "import itertools  # Iteration utilities\n",
        "import math  # Mathematical operations\n",
        "import json  # JSON (JavaScript Object Notation) handling\n",
        "#import torch_geometric  # For GCN implementation in PyTorch\n",
        "#from torch_geometric.nn import GCNConv  # GCN convolution layer\n",
        "import networkx as nx  # For graph manipulation\n",
        "\n",
        "# Check if CUDA (GPU support) is available, and set the device accordingly\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function printLines that reads and prints the first 'n' lines from a given file. Then, it calls this function with the path to the \"utterances.jsonl\" file within the \"movie-corpus\" directory:"
      ],
      "metadata": {
        "id": "z8Drcefmv_vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCJtfxyhzi_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b22408-d83e-40dc-fbc7-7195f29977b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
          ]
        }
      ],
      "source": [
        "import os  # Import the 'os' module to work with file paths.\n",
        "\n",
        "# Define the name of the corpus folder.\n",
        "corpus_name = \"movie-corpus\"\n",
        "\n",
        "# Create a file path by joining \"data\" and the corpus_name.\n",
        "corpus = os.path.join(\"movie-corpus\", corpus_name)\n",
        "\n",
        "# Define a function called 'printLines' that takes a file path and an optional argument 'n'.\n",
        "def printLines(file, n=10):\n",
        "    # Open the file in binary read mode and assign it to the 'datafile' variable.\n",
        "    with open(file, 'rb') as datafile:\n",
        "        # Read all lines from the file and store them in the 'lines' list.\n",
        "        lines = datafile.readlines()\n",
        "\n",
        "    # Loop through the first 'n' lines (default is 10) in the 'lines' list.\n",
        "    for line in lines[:n]:\n",
        "        # Print each line to the console.\n",
        "        print(line)\n",
        "\n",
        "# Call the 'printLines' function with the file path to \"utterances.jsonl\" in the 'corpus' folder.\n",
        "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions are used for loading lines and conversations from a file, as well as extracting pairs of sentences from those conversations:"
      ],
      "metadata": {
        "id": "pwny8N3fwQ2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyEito6xzi_R"
      },
      "outputs": [],
      "source": [
        "# Function to load lines and conversations from a file\n",
        "def loadLinesAndConversations(fileName):\n",
        "    lines = {}  # Dictionary to store individual lines\n",
        "    conversations = {}  # Dictionary to store conversations\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            lineJson = json.loads(line)  # Parse the JSON data from each line\n",
        "            # Extract fields for line object\n",
        "            lineObj = {}\n",
        "            lineObj[\"lineID\"] = lineJson[\"id\"]\n",
        "            lineObj[\"characterID\"] = lineJson[\"speaker\"]\n",
        "            lineObj[\"text\"] = lineJson[\"text\"]\n",
        "            lines[lineObj['lineID']] = lineObj  # Store the line object in the 'lines' dictionary\n",
        "\n",
        "            # Extract fields for conversation object\n",
        "            if lineJson[\"conversation_id\"] not in conversations:\n",
        "                convObj = {}\n",
        "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
        "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
        "                convObj[\"lines\"] = [lineObj]\n",
        "            else:\n",
        "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
        "                convObj[\"lines\"].insert(0, lineObj)\n",
        "            conversations[convObj[\"conversationID\"]] = convObj  # Store the conversation object in the 'conversations' dictionary\n",
        "\n",
        "    return lines, conversations\n",
        "\n",
        "\n",
        "# Function to extract pairs of sentences from conversations\n",
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []  # List to store question-answer pairs\n",
        "    for conversation in conversations.values():\n",
        "        # Iterate over all the lines of the conversation\n",
        "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line\n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "            # Filter out wrong samples (if one of the lists is empty)\n",
        "            if inputLine and targetLine:\n",
        "                qa_pairs.append([inputLine, targetLine])  # Add the pair to the list\n",
        "    return qa_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnIkhMULzi_R"
      },
      "source": [
        "This code prepares and processes data from the \"utterances.jsonl\" file, formats it, and saves it to a new CSV file named \"formatted_movie_lines.txt.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6grhS9BSzi_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb98848d-52c7-4b2f-939c-607d4df0a8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing corpus into lines and conversations...\n",
            "\n",
            "Writing newly formatted file...\n",
            "\n",
            "Sample lines from file:\n",
            "b'They do to!\\tThey do not!\\n'\n",
            "b'She okay?\\tI hope so.\\n'\n",
            "b\"Wow\\tLet's go.\\n\"\n",
            "b'\"I\\'m kidding.  You know how sometimes you just become this \"\"persona\"\"?  And you don\\'t know how to quit?\"\\tNo\\n'\n",
            "b\"No\\tOkay -- you're gonna need to learn how to lie.\\n\"\n",
            "b\"I figured you'd get to the good stuff eventually.\\tWhat good stuff?\\n\"\n",
            "b'What good stuff?\\t\"The \"\"real you\"\".\"\\n'\n",
            "b'\"The \"\"real you\"\".\"\\tLike my fear of wearing pastels?\\n'\n",
            "b'do you listen to this crap?\\tWhat crap?\\n'\n",
            "b\"What crap?\\tMe.  This endless ...blonde babble. I'm like, boring myself.\\n\"\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the new file where formatted data will be saved\n",
        "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
        "\n",
        "# Define the delimiter used to separate values in the CSV file\n",
        "delimiter = '\\t'\n",
        "\n",
        "# Unescape the delimiter to handle escape sequences if necessary\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "\n",
        "# Initialise dictionaries to store lines and conversations\n",
        "lines = {}  # Dictionary to store individual lines\n",
        "conversations = {}  # Dictionary to store conversations\n",
        "\n",
        "# Load lines and conversations from the \"utterances.jsonl\" file\n",
        "print(\"\\nProcessing corpus into lines and conversations...\")\n",
        "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"))\n",
        "\n",
        "# Write the newly formatted data to a CSV file\n",
        "print(\"\\nWriting newly formatted file...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
        "    for pair in extractSentencePairs(conversations):\n",
        "        writer.writerow(pair)\n",
        "\n",
        "# Print a sample of lines from the newly created file\n",
        "print(\"\\nSample lines from file:\")\n",
        "printLines(datafile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOEP-YQNzi_S"
      },
      "source": [
        "This code defines a 'Voc' class for managing a vocabulary, adding words and sentences to it, and trimming it by removing words with low counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MpOOoDZzi_S"
      },
      "outputs": [],
      "source": [
        "# Define default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token\n",
        "\n",
        "# Define a vocabulary class to manage word-to-index and index-to-word mappings\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name  # Name of the vocabulary\n",
        "        self.trimmed = False  # Flag to indicate if vocabulary has been trimmed\n",
        "        self.word2index = {}  # Dictionary mapping words to their index\n",
        "        self.word2count = {}  # Dictionary to store word counts\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}  # Dictionary mapping indices to words with default tokens\n",
        "        self.num_words = 3  # Initialise the count of words with default tokens (PAD, SOS, EOS)\n",
        "\n",
        "    # Method to add a sentence to the vocabulary\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    # Method to add a word to the vocabulary\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            # If the word is not in the vocabulary, add it\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            # If the word is already in the vocabulary, increment its count\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Method to trim the vocabulary by removing words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # Reinitialise dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Reset word count to include default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcYbL2Xlzi_T"
      },
      "source": [
        "This code prepares training data by reading and normalizing pairs of sentences, filtering them based on sentence length, and creating a vocabulary object ('Voc') to manage word-to-index mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8FWpwXWzi_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8f3154-670a-45bc-a15a-5168968a01d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data ...\n",
            "Reading lines...\n"
          ]
        }
      ],
      "source": [
        "# Maximum sentence length to consider\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "# Function to convert Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Function to normalize a string: lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())  # Convert to lowercase and strip spaces\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)  # Add spaces around punctuation\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)  # Remove non-letter characters\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()  # Remove extra spaces and strip\n",
        "    return s\n",
        "\n",
        "# Function to read query/response pairs and return a 'Voc' object and pairs list\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split it into lines\n",
        "    lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
        "    # Split every line into pairs and normalize them\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    # Create a 'Voc' object with the given 'corpus_name'\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs\n",
        "\n",
        "# Function to filter pairs based on sentence length (under MAX_LENGTH)\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "# Function to filter pairs using the 'filterPair' condition\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "# Function to load and prepare training data, returning a populated 'Voc' object and pairs list\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Start preparing training data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Counted words:\", voc.num_words)\n",
        "    return voc, pairs\n",
        "\n",
        "# Define a save directory for the 'Voc' object and pairs list\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "\n",
        "# Load and prepare data using the functions defined above\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "\n",
        "# Print some example pairs to validate the data\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpdDsCQxzi_T"
      },
      "source": [
        "This code defines a function 'trimRareWords' to trim rare words from the vocabulary ('voc') and filter pairs that do not contain trimmed words in their input or output sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu5VIRagzi_T"
      },
      "outputs": [],
      "source": [
        "# Minimum word count threshold for trimming\n",
        "MIN_COUNT = 3\n",
        "\n",
        "# Function to trim rare words from the vocabulary and filter pairs\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used less than MIN_COUNT times from the vocabulary\n",
        "    voc.trim(MIN_COUNT)\n",
        "\n",
        "    # Initialise a list to keep pairs that do not contain trimmed words\n",
        "    keep_pairs = []\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "# Trim rare words from the vocabulary and filter pairs\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK0xOgc_zi_T"
      },
      "source": [
        "These functions prepare the input and output tensors for training data, including padding and creating binary masks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FebgmPKzzi_U"
      },
      "outputs": [],
      "source": [
        "# Function to convert a sentence to a list of indexes using the vocabulary\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "# Function to pad sequences with zeros to create a rectangular matrix\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "# Function to create a binary matrix indicating the presence of padding tokens\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Function to prepare input sequence tensor and lengths\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Function to prepare target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Function to prepare all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    # Sort the pair batch by the length of the input sequences (for efficient padding)\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "# Example code for validation\n",
        "small_batch_size = 5\n",
        "# Create batches of training data with random pairs\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "# Print the prepared data for validation\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification and Testing:"
      ],
      "metadata": {
        "id": "xuD9DgbZwP7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for metrics and plotting\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define sample test data as a list of tuples (input text, expected category)\n",
        "test_data = [\n",
        "    (\"Hello, how are you?\", \"Greeting\"),\n",
        "    (\"What time is it?\", \"Informational\"),\n",
        "    (\"Goodbye and take care!\", \"Farewell\"),\n",
        "    (\"I am happy\", \"Informational\"),\n",
        "    (\"Who are you?\", \"Clarification\")\n",
        "]\n",
        "\n",
        "# Define the categories for classification\n",
        "categories = ['Greeting', 'Farewell', 'Informational', 'Clarification', 'Other']\n",
        "\n",
        "# Function to generate chatbot response based on input text\n",
        "def chatbot_response(input_text):\n",
        "    # Placeholder logic for chatbot responses\n",
        "    if \"hello\" in input_text.lower():\n",
        "        return \"Hello there!\"\n",
        "    elif \"time\" in input_text.lower():\n",
        "        return \"It's 10 AM.\"\n",
        "    elif \"goodbye\" in input_text.lower():\n",
        "        return \"Farewell!\"\n",
        "    else:\n",
        "        return \"I am not sure how to respond to that.\"\n",
        "\n",
        "# Function to classify responses into predefined categories\n",
        "def classify_response(response):\n",
        "    # Basic classification based on keywords\n",
        "    if any(word in response.lower() for word in [\"hello\", \"hi\"]):\n",
        "        return \"Greeting\"\n",
        "    elif any(word in response.lower() for word in [\"bye\", \"farewell\", \"goodbye\"]):\n",
        "        return \"Farewell\"\n",
        "    elif any(word in response.lower() for word in [\"time\", \"when\"]):\n",
        "        return \"Informational\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "# Lists to store expected and predicted response categories\n",
        "expected = []\n",
        "predicted = []\n",
        "\n",
        "# Loop over test data to evaluate chatbot responses\n",
        "for input_text, expected_response in test_data:\n",
        "    # Get actual response from chatbot and classify both expected and actual responses\n",
        "    actual_response = chatbot_response(input_text)\n",
        "    expected.append(classify_response(expected_response))\n",
        "    predicted.append(classify_response(actual_response))\n",
        "\n",
        "# Generate and plot confusion matrix\n",
        "conf_matrix = confusion_matrix(expected, predicted, labels=categories)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=categories, yticklabels=categories)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GLk0I6ZvwQJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GCNN:\n",
        "x = F.relu(self.conv1(x)):\n",
        "\n",
        "Applies the first convolutional layer (conv1) to the input x.\n",
        "The relu (Rectified Linear Unit) activation function is then applied to the output of conv1.\n",
        "x = torch.bmm(adj, x):\n",
        "\n",
        "Performs a batch matrix-matrix product of the adjacency matrix adj and the result from the first convolution.\n",
        "This step integrates the graph structure into the network by using the adjacency matrix.\n",
        "x = self.conv2(x):\n",
        "\n",
        "Applies the second convolutional layer (conv2) to the result of the matrix multiplication.\n",
        "return F.relu(x):\n",
        "\n",
        "Finally, applies the relu activation function to the output of the second convolutional layer and returns this result."
      ],
      "metadata": {
        "id": "RYNDxWBeyO11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.conv1(x))  # Apply the first convolution\n",
        "        x = torch.bmm(adj, x.transpose(1, 2)).transpose(1, 2)  # Fix the batch matrix multiplication\n",
        "        x = self.conv2(x)  # Apply the second convolution\n",
        "        return F.relu(x)\n",
        "\n",
        "# Function to create a graph from an adjacency matrix\n",
        "def create_graph_from_adjacency_matrix(adj_matrix):\n",
        "    G = nx.Graph()\n",
        "    for i in range(len(adj_matrix)):\n",
        "        for j in range(len(adj_matrix)):\n",
        "            if adj_matrix[i, j] == 1:\n",
        "                G.add_edge(i, j)\n",
        "    return G\n",
        "\n",
        "# Function to draw a tree from a graph\n",
        "def draw_tree(G, root_node):\n",
        "    tree = nx.bfs_tree(G, source=root_node)\n",
        "    nx.draw(tree, with_labels=True, node_color='lightblue', node_size=500, font_size=10)\n",
        "    plt.show()\n",
        "\n",
        "# Example values for in_channels and out_channels\n",
        "in_channels = 128\n",
        "out_channels = 64\n",
        "\n",
        "# Sample input data and adjacency matrix\n",
        "input_data = torch.randn(1, in_channels, 10)  # Shape should be [batch_size=1, channels=128, sequence_length=10]\n",
        "adj_matrix = torch.ones(10, 10)  # Shape should be [sequence_length=10, sequence_length=10]\n",
        "\n",
        "# Add batch dimension to adj_matrix\n",
        "adj_matrix = adj_matrix.unsqueeze(0)  # Shape should be [batch_size=1, sequence_length=10, sequence_length=10]\n",
        "\n",
        "gcnn = GCNN(in_channels=in_channels, out_channels=out_channels)\n",
        "gcnn_output = gcnn(input_data, adj_matrix)\n",
        "\n",
        "# Create and visualize the graph\n",
        "G = create_graph_from_adjacency_matrix(adj_matrix.squeeze())  # Remove the batch dimension for visualisation\n",
        "draw_tree(G, root_node=0)  # Specify the root node for the tree"
      ],
      "metadata": {
        "id": "jNwnp14jyO-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrating GCN Features into Chatbot:\n",
        "\n",
        "Here I have made some changes to the architecture and added additional layers, this made the output worse with the chatbot reverting to nosensical responses. After this I reverted back to my original code for the GCN."
      ],
      "metadata": {
        "id": "FZE0JM6c9yPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Define the Graph Convolutional Network (GCN) model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Example: Define your chatbot model here\n",
        "class ChatBotModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(ChatBotModel, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.fc(x))\n",
        "\n",
        "# Function to integrate GCN output with the chatbot\n",
        "def integrate_gcn_with_chatbot(gcn_model, chatbot_model, graph_data):\n",
        "    # Extract features with GCN\n",
        "    gcn_features = gcn_model(graph_data.x, graph_data.edge_index)\n",
        "\n",
        "    # Use the GCN features in the chatbot model\n",
        "    chatbot_output = chatbot_model(gcn_features)\n",
        "    return chatbot_output\n",
        "\n",
        "# Number of nodes\n",
        "num_nodes = 4\n",
        "\n",
        "# Node features (each node has 3 features)\n",
        "node_features = torch.tensor([[0.5, 1.0, 0.5],  # Features for node 1\n",
        "                              [0.1, 0.2, 0.6],  # Features for node 2\n",
        "                              [0.7, 0.4, 0.3],  # Features for node 3\n",
        "                              [0.3, 0.8, 0.1]], # Features for node 4\n",
        "                             dtype=torch.float)\n",
        "\n",
        "# Edges (undirected edges represented as two directed edges)\n",
        "edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],  # Source nodes\n",
        "                           [1, 0, 2, 1, 3, 2]], # Target nodes\n",
        "                          dtype=torch.long)\n",
        "\n",
        "# Create graph data\n",
        "graph_data = Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "# Initialize GCN model with appropriate values\n",
        "gcn_model = GCN(num_node_features=3, hidden_channels=16)\n",
        "\n",
        "# Initialize chatbot model with appropriate values\n",
        "chatbot_model = ChatBotModel(input_size=16, hidden_size=32)\n",
        "\n",
        "# Integrate GCN output with chatbot\n",
        "integrated_output = integrate_gcn_with_chatbot(gcn_model, chatbot_model, graph_data)"
      ],
      "metadata": {
        "id": "Aq_TO22T9yaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsZYHHa0zi_U"
      },
      "source": [
        "### Encoder ###\n",
        "This EncoderRNN class is a part of a sequence-to-sequence (seq2seq) model. It takes input sequences, processes them through a bidirectional GRU (Gated Recurrent Unit), and returns the outputs and the final hidden state:\n",
        "\n",
        "In the modified EncoderRNN class, I made several key changes:\n",
        "\n",
        "RNN Type Changed: I switched the RNN type from nn.GRU to nn.LSTM. This alteration introduced LSTM cells, which include both hidden states and cell states, potentially improving the model's ability to capture long-term dependencies.\n",
        "\n",
        "Hidden Dimension Increased: I increased the hidden_size parameter, which determines the size of the hidden states within the LSTM. A larger hidden dimension can enhance the model's capacity to represent complex patterns.\n",
        "\n",
        "Bidirectional LSTM: I configured the LSTM to be bidirectional by default. This means it captures information from both past and future contexts for each time step, potentially improving context understanding.\n",
        "\n",
        "Other Parameters Unchanged: I retained the n_layers and dropout parameters, allowing flexibility to specify the number of layers and control dropout regularization as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iQcjXVazi_W"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size parameters are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with a number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9oq1g1mzi_W"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "This Attn class is used for implementing different attention mechanisms (dot, general, concat) in a sequence-to-sequence (seq2seq) model. It calculates attention scores based on the chosen method and returns softmax-normalized probability scores:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deLHyzPxzi_W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            # Linear layer for general attention\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            # Linear layers for concat attention\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        # Calculate dot product attention scores\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        # Calculate general attention scores\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        # Calculate concat attention scores\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac2n9OnMzi_X"
      },
      "source": [
        "This 'LuongAttnDecoderRNN' class is a part of a sequence-to-sequence (seq2seq) model with Luong attention. It takes an input step (word), processes it through a GRU, calculates attention scores, and produces an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHzWG8MKzi_X"
      },
      "outputs": [],
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize attention mechanism\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of the current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights with encoder outputs to get the new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Squeeze dimensions to match shapes for concatenation\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        # Concatenate weighted context vector and GRU output using Luong Eq. 5\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict the next word using Luong Eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return the output and the final hidden state\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqm-zsJozi_X"
      },
      "source": [
        "## Define Training Procedure\n",
        "\n",
        "### Masked loss\n",
        "\n",
        "This function is used to calculate the negative log-likelihood loss for a sequence of inputs and target indices while handling padding elements using a binary mask.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLhSP278zi_X"
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    # Calculate the negative log-likelihood loss for a sequence of inputs ('inp') and target indices ('target')\n",
        "    # masked by a binary mask ('mask') to handle padding.\n",
        "\n",
        "    # Calculate the total number of elements (tokens) in the batch\n",
        "    nTotal = mask.sum()\n",
        "\n",
        "    # Use the 'gather' function to select the predicted probabilities corresponding to the target indices\n",
        "    # and calculate the cross-entropy loss\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "\n",
        "    # Mask the loss using the provided binary mask to ignore padding elements\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "\n",
        "    # Ensure the loss is on the same device as the input\n",
        "    loss = loss.to(device)\n",
        "\n",
        "    # Return the masked loss and the total number of non-padding elements in the batch\n",
        "    return loss, nTotal.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4g0zrs-zi_X"
      },
      "source": [
        "### Single training iteration\n",
        "\n",
        "This train function is used to train a sequence-to-sequence model with teacher forcing. It performs a forward pass through the encoder and decoder, calculates the loss, and performs backpropagation to update the model weights:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gal7ubGHzi_X"
      },
      "outputs": [],
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for RNN packing should always be on the CPU\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialise variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BpUnJgCzi_Y"
      },
      "source": [
        "### Training iterations\n",
        "\n",
        "This trainIters function is used to train a sequence-to-sequence model for a specified number of iterations. It loads batches of training data, runs training iterations, and saves checkpoints at specified intervals:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d1kpfuHzi_Y"
      },
      "outputs": [],
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # Load batches for each iteration\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initialisations\n",
        "    print('Initialising ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        # Extract fields from the batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # Run a training iteration with the batch\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "        print_loss += loss\n",
        "\n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-dpwGMWzi_Y"
      },
      "source": [
        "## Define Evaluation\n",
        "\n",
        "### Greedy decoding\n",
        "This GreedySearchDecoder class is used for performing greedy decoding with a trained encoder-decoder model. It takes an input sequence, feeds it through the encoder, and then iteratively generates the most likely output sequence one token at a time using the decoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shckFdbXzi_Y"
      },
      "outputs": [],
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be the first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain the most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare the current token to be the next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NijbRg0vzi_Y"
      },
      "source": [
        "### Evaluate my text\n",
        "\n",
        "These functions are used for evaluating input sentences using a trained encoder-decoder model and a searcher (e.g., GreedySearchDecoder). The evaluate function takes an input sentence, processes it, and generates a response based on the model's predictions. The evaluateInput function allows users to interact with the model by providing input sentences and receiving responses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZVqt17dzi_Y"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of the batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use the appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is a quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit':\n",
        "                break\n",
        "            # Normalise sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # Format and print the response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered an unknown word.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcIqg9XNzi_Z"
      },
      "source": [
        "## Run Model\n",
        "\n",
        "These configurations define various aspects of your model, such as its name, attention mechanism, hidden size, number of layers, dropout rate, batch size, and whether you want to load a pretrained model checkpoint:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYBTBixGzi_Z"
      },
      "outputs": [],
      "source": [
        "# Configure models\n",
        "model_name = 'cb_model'  # Choose a name for your model\n",
        "#attn_model = 'dot'       # Choose an attention mechanism: 'dot', 'general', or 'concat'\n",
        "attn_model = 'general'  # Uncomment this line to use the 'general' attention mechanism\n",
        "#attn_model = 'concat'   # Uncomment this line to use the 'concat' attention mechanism\n",
        "hidden_size = 500        # Define the hidden size for the encoder and decoder\n",
        "encoder_n_layers = 2     # Number of layers for the encoder\n",
        "decoder_n_layers = 2     # Number of layers for the decoder\n",
        "dropout = 0.01            # Dropout probability for the model\n",
        "batch_size = 128         # Batch size for training\n",
        "\n",
        "# Set checkpoint to load from; set to None if starting from scratch\n",
        "loadFilename = None      # Set to a file path if you want to load a pretrained model checkpoint\n",
        "checkpoint_iter = 4000  # Specify the checkpoint iteration to load (if loadFilename is not None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_CXr0D2zi_Z"
      },
      "source": [
        "Sample code to load from a checkpoint:\n",
        "\n",
        "```python\n",
        "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "                    '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "                    '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZb7AyNnzi_e"
      },
      "outputs": [],
      "source": [
        "# Load model if a `loadFilename` is provided\n",
        "if loadFilename:\n",
        "    # If loading on the same machine the model was trained on\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU, use the following line instead\n",
        "    # checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Load model weights and other relevant data\n",
        "    encoder_sd = checkpoint['en']                    # Encoder state dictionary\n",
        "    decoder_sd = checkpoint['de']                    # Decoder state dictionary\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']      # Encoder optimizer state dictionary\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']      # Decoder optimizer state dictionary\n",
        "    embedding_sd = checkpoint['embedding']           # Embedding state dictionary\n",
        "    voc.__dict__ = checkpoint['voc_dict']             # Vocabulary dictionary\n",
        "\n",
        "# Initialise word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "\n",
        "# Initialise encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "\n",
        "if loadFilename:\n",
        "    # Load the pretrained model weights\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "\n",
        "# Move models to the appropriate device (GPU or CPU)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "print('Models built and ready to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCkK_dtpzi_e"
      },
      "source": [
        "### Run Training ###\n",
        "\n",
        "This code block sets up various training parameters, including gradient clipping, teacher forcing ratio, learning rates, and the number of training iterations. It also initializes the optimizer for both the encoder and decoder. Finally, it starts the training loop by calling the trainIters function with the provided parameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs4LAMrszi_f"
      },
      "outputs": [],
      "source": [
        "# Configure training/optimisation\n",
        "clip = 50.0                   # Gradient clipping threshold to prevent exploding gradients\n",
        "teacher_forcing_ratio = 0.7   # Probability of using teacher forcing during training (1.0 means always)\n",
        "learning_rate = 0.0001        # Learning rate for the optimiser\n",
        "decoder_learning_ratio = 5.0  # Learning rate multiplier for the decoder compared to the encoder\n",
        "n_iteration = 5000            # Number of training iterations\n",
        "print_every = 500           # Print training progress every `print_every` iterations\n",
        "save_every = 500             # Save a checkpoint every `save_every` iterations\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialise optimisers\n",
        "print('Building optimisers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "# Load optimiser states if a checkpoint is provided\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# If you have CUDA, configure CUDA to call\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9bVadTTzi_f"
      },
      "source": [
        "### Run Evaluation\n",
        "\n",
        "To chat with your model, run the following block.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_N5hle9zi_f"
      },
      "outputs": [],
      "source": [
        "# Set dropout layers to ``eval`` mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialise search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Begin chatting (uncomment and run the following line to begin)\n",
        "evaluateInput(encoder, decoder, searcher, voc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}